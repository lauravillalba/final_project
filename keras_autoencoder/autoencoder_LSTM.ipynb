{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, LSTM, RepeatVector\n",
    "from keras.models import Model\n",
    "from pydub import AudioSegment\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.DataFrame()\n",
    "\n",
    "df['path'] = glob.glob(\"../outputs/splited_audio/**.mp3\")\n",
    "\n",
    "df['id_person'] = df.path.apply(lambda x: (x.split(\"/\")[3]).split('_')[0])\n",
    "df['id_audio'] = df.path.apply(lambda x: ((x.split(\"/\")[3]).split('_')[1]).split('.')[0])\n",
    "df['array'] = df.path.apply(lambda x: (list(AudioSegment.from_file(x, format='mp3').get_array_of_samples())))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "df.to_csv('../outputs/df_for_autoencoder.csv', index=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>id_person</th>\n",
       "      <th>id_audio</th>\n",
       "      <th>array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../outputs/splited_audio/2414_4.mp3</td>\n",
       "      <td>2414</td>\n",
       "      <td>4</td>\n",
       "      <td>[14, 171, 155, -18, -94, -38, -87, -231, -209,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../outputs/splited_audio/3080_4.mp3</td>\n",
       "      <td>3080</td>\n",
       "      <td>4</td>\n",
       "      <td>[-957, -1389, -1545, -1610, -1693, -1791, -177...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../outputs/splited_audio/2033_10.mp3</td>\n",
       "      <td>2033</td>\n",
       "      <td>10</td>\n",
       "      <td>[3, 3, 2, 2, 2, 3, 1, 1, 1, 0, -1, 0, 0, 1, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../outputs/splited_audio/3997_9.mp3</td>\n",
       "      <td>3997</td>\n",
       "      <td>9</td>\n",
       "      <td>[48, -40, -60, 50, 17, -92, 27, 173, 3, -211, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../outputs/splited_audio/3764_12.mp3</td>\n",
       "      <td>3764</td>\n",
       "      <td>12</td>\n",
       "      <td>[110, 380, 570, 515, 154, -473, -978, -922, -4...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   path id_person id_audio  \\\n",
       "0   ../outputs/splited_audio/2414_4.mp3      2414        4   \n",
       "1   ../outputs/splited_audio/3080_4.mp3      3080        4   \n",
       "2  ../outputs/splited_audio/2033_10.mp3      2033       10   \n",
       "3   ../outputs/splited_audio/3997_9.mp3      3997        9   \n",
       "4  ../outputs/splited_audio/3764_12.mp3      3764       12   \n",
       "\n",
       "                                               array  \n",
       "0  [14, 171, 155, -18, -94, -38, -87, -231, -209,...  \n",
       "1  [-957, -1389, -1545, -1610, -1693, -1791, -177...  \n",
       "2  [3, 3, 2, 2, 2, 3, 1, 1, 1, 0, -1, 0, 0, 1, 2,...  \n",
       "3  [48, -40, -60, 50, 17, -92, 27, 173, 3, -211, ...  \n",
       "4  [110, 380, 570, 515, 154, -473, -978, -922, -4...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''df = pd.read_csv('../outputs/df_for_autoencoder.csv')\n",
    "'''\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(899,) (899, 320000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "y = df['id_person'].to_numpy()\n",
    "X = np.vstack(df['array'])\n",
    "\n",
    "print(y.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   14,   171,   155, ...,    -4,     1,     4],\n",
       "       [ -957, -1389, -1545, ...,     0,     0,     0],\n",
       "       [    3,     3,     2, ...,   -53,   -54,   -41],\n",
       "       ...,\n",
       "       [   -9,     7,    -4, ...,    -3,    -9,   -12],\n",
       "       [  -24,   -25,   -20, ...,     8,    13,    18],\n",
       "       [   20,     2,   -28, ...,   107,   104,    75]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(719, 320000) (180, 320000) (719,) (180,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(719, 6400, 50) (719,) (180, 6400, 50) (180,)\n"
     ]
    }
   ],
   "source": [
    "#XTr = X_train.reshape((X_train.shape[0],8000,40))\n",
    "#yTr = y_train\n",
    "#XT = X_test.reshape((X_test.shape[0],8000,40))\n",
    "#yT = y_test\n",
    "\n",
    "XTr = np.expand_dims(X_train,axis=2).reshape((X_train.shape[0],X_train.shape[1]//50,50))\n",
    "yTr = y_train\n",
    "XT = np.expand_dims(X_test,axis=2).reshape((X_test.shape[0],X_test.shape[1]//50,50))\n",
    "yT = y_test\n",
    "\n",
    "print(XTr.shape,yTr.shape,XT.shape,yT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, activation='relu', input_shape=(n_in,1)))\n",
    "model.add(RepeatVector(n_in))\n",
    "model.add(LSTM(100, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input dimensions:719 Timesteps:320000\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_26 (LSTM)               (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "repeat_vector_16 (RepeatVect (None, 6400, 50)          0         \n",
      "_________________________________________________________________\n",
      "lstm_27 (LSTM)               (None, 6400, 50)          20200     \n",
      "_________________________________________________________________\n",
      "time_distributed_12 (TimeDis (None, 6400, 1)           51        \n",
      "=================================================================\n",
      "Total params: 40,451\n",
      "Trainable params: 40,451\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "input_dim, timesteps = X_train.shape\n",
    "print(f\"Input dimensions:{input_dim} Timesteps:{timesteps}\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(timesteps//50,50)))\n",
    "model.add(RepeatVector(timesteps//50))\n",
    "model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(1)))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "'''\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(timesteps//50,50)))\n",
    "model.add(LSTM(30,return_sequences=True))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')'''\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected time_distributed_12 to have 3 dimensions, but got array with shape (719, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-60bafbbbf833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                 validation_data=(XT, yT))\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    619\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    133\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    136\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected time_distributed_12 to have 3 dimensions, but got array with shape (719, 1)"
     ]
    }
   ],
   "source": [
    "# fit model\n",
    "#model.fit(X_train,X_train, epochs=300, verbose=0)\n",
    "\n",
    "model.fit(XTr, yTr,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(XT, yT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_shapes=True, to_file='reconstruct_lstm_autoencoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demonstrate recreation\n",
    "yhat = model.predict(sequence, verbose=0)\n",
    "#print(yhat[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/how-to-generate-music-using-a-lstm-neural-network-in-keras-68786834d4c5\n",
    "# https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/\n",
    "# https://machinelearningmastery.com/reshape-input-data-long-short-term-memory-networks-keras/\n",
    "\n",
    "input_dim, timesteps = X_train.shape\n",
    "print(f\"Input dimensions:{input_dim} Timesteps:{timesteps}\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(timesteps//50,50)))\n",
    "model.add(LSTM(30,return_sequences=True))\n",
    "\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XTr = X_train.reshape((X_train.shape[0],8000,40))\n",
    "#yTr = y_train\n",
    "#XT = X_test.reshape((X_test.shape[0],8000,40))\n",
    "#yT = y_test\n",
    "\n",
    "\n",
    "\n",
    "XTr = np.expand_dims(X_train,axis=2).reshape((X_train.shape[0],X_train.shape[1]//50,50))\n",
    "yTr = y_train\n",
    "XT = np.expand_dims(X_test,axis=2).reshape((X_test.shape[0],X_train.shape[1]//50,50))\n",
    "yT = y_test\n",
    "\n",
    "print(XTr.shape,yTr.shape,XT.shape,yT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(XTr, yTr,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(XT, yT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
